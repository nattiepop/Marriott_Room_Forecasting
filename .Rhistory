plot(consumer.pca, type="l")
summary(consumer.pca)
pc<-predict(consumer.pca , newdata = ConsumerIndex[,-6])
head(pc)
newdf<-data.frame(PC1=pc[,1], PC2=pc[,2], housing=ConsumerIndex[,6])
head(newdf)
modelPC<-lm(housing~., data=newdf)
summary(modelPC)
plot(resid(model))
par(mfrow=c(1,1))
plot(resid(model))
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv('InAppPurchase.csv', header = T, sep = ",")
summary(data)
head(data)
summary(data)
logitplot<-function(y,x,ncat=40,...)
{
brksx<-unique(quantile(x,probs=(0:ncat)/ncat))
nbrksx<-length(brksx)
cutx<-cut(x,breaks=brksx,include.lowest=TRUE)
yt<-table(data.frame(y,cutx))
mx<-tapply(x,cutx,FUN=mean)
logity<-log((yt[2,]+0.5)/(yt[1,]+0.5))
plot(mx,logity,...)
}
par(mfrow=c(4,2))
logitplot(Buy, Age, xlab="Age", ylab="adjusted sample logit")
logitplot(Buy, Age, xlab="Age", ylab="Buy")
attach(data)
logitplot(Buy, Age, xlab="Age", ylab="Buy")
logitplot(Age, Buy, xlab="Age", ylab="Buy")
plot(Age, Buy, xlab="Age", ylab="Buy")
plot(Buy, Age, xlab="Age", ylab="Buy")
boxplot(Buy, Age, xlab="Age", ylab="Buy")
boxplot(Age, Buy, xlab="Age", ylab="Buy")
summary(data)
par(mfrow=c(4,2))
boxplot(Age, Buy)
boxplot(Sex, Buy)
boxplot(Income, Buy)
boxplot(Months, Buy)
boxplot(Hours, Buy)
boxplot(CreditCard, Buy)
boxplot(Facebook, Buy)
par(mfrow=c(3,3))
par(mfrow=c(3,3))
boxplot(Age, Buy)
boxplot(Sex, Buy)
boxplot(Income, Buy)
boxplot(Months, Buy)
boxplot(Hours, Buy)
boxplot(CreditCard, Buy)
boxplot(Facebook, Buy)
fmod <- glm(Buy~., data=data, family=binomial(link="logit"))
summary(fmod)
plot(fmod, 1)
plot(fmod, 2)
plot(fmod, 3)
plot(fmod, 4)
par(mfrow=c(3,1))
par(mfrow=c(3,1))
plot(fmod, 1)
plot(fmod, 2)
plot(fmod, 4)
par(mfrow=c(1,3))
par(mfrow=c(1,3))
plot(fmod, 1)
plot(fmod, 2)
plot(fmod, 4)
par(mfrow=c(1,2))
plot(fmod, 1)
plot(fmod, 2)
library(olsrr)
ols_plot_resid_lev(model)
library(olsrr)
ols_plot_resid_lev(fmod)
library(olsrr)
ols_plot_cooksd_bar(fmod)
plot(fmod,4)
influence.measures(fmod)
plot(fmod,4)
newdata <- data[-c(2,3,14)]
fmod <- glm(Buy~., data=newdata, family=binomial(link="logit"))
summary(fmod)
par(mfrow=c(1,2))
plot(fmod,1)
plot(fmod,2)
mod1 <- step(fmod)
summary(mod1)
mod1 <- step(fmod, direction ="backward", k= log(nrow(newdata)))
summary(mod1)
par(mfrow=c(1,2))
plot(mod1,1)
plot(mod2,2)
plot(mod1,2)
par(mfrow=c(1,2))
plot(mod1,1)
plot(mod1,2)
plot(mod1,4)
influence.measures(mod1)
# Shapiro-Wilk Test
shapiro.test(resid(model))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(model1)
# Shapiro-Wilk Test
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(model))
# Durbin-Watson Test
dwtest(model)
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(mod1))
# Durbin-Watson Test
dwtest(mod1)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod1$fitted.values)
LRT <- deviance(mod1) - deviance(fmod)
1-pchisq(LRT, df.residual(mod)-df.residual(fmod))
1-pchisq(LRT, df.residual(mod1)-df.residual(fmod))
summary(mod1)
predv <- data.frame(Age = 22, Sex = 0, Income = 20, Months = 6, Hours = 25, CreditCard = 0, Facebook = 1)
plink <- predict(mod1, newdata=predv, se.fit=T, type="link")
predv <- data.frame(Age = 22, Sex = 0, Income = 20, Months = 6, Hours = 25, CreditCard = 0, Facebook = 1)
predict(mod1, newdata=predv, se.fit=T, type="link")
pchisq(deviance(mod1), df.residual(mod1), lower=FALSE)
predict(mod1, newdata=predv, se.fit=T, type="response")
mod1 <- step(fmod, direction = "both", trace = 0)
summary(mod1)
drop1(fmod, test="F")
newdata <- data[-c(2,3,14),]
fmod <- glm(Buy~., data=data, family=binomial(link="logit"))
summary(fmod)
fmod <- glm(Buy~., data=newdata, family=binomial(link="logit"))
summary(fmod)
mod1 <- step(fmod, direction = "both", trace = 0)
summary(mod1)
mod1 <- step(fmod, direction ="backward", k= log(nrow(newdata)))
summary(mod1)
par(mfrow=c(1,2))
plot(mod1,1)
plot(mod1,2)
mod1 <- step(fmod, direction ="backward", k= log(nrow(newdata)))
summary(mod1)
par(mfrow=c(1,2))
plot(mod1,1)
plot(mod1,2)
plot(mod1,4)
newdata <- newdata[-c(4,37,395),]
mod2 <- glm(Buy~Income+Months+CreditCard, data=newdata, family=binomial(link="logit"))
summary(mod2)
# Shapiro-Wilk Test
shapiro.test(resid(mod2))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod2)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(mod2))
# Durbin-Watson Test
dwtest(mod2)
pchisq(deviance(mod2), df.residual(mod2), lower=FALSE)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod2$fitted.values)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod2$fitted.values)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod1$fitted.values)
hosmerlem(Buy, mod2$fitted.values)
hosmerlem <-function (y, yhat, g = 5)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod2$fitted.values)
plot(mod1,4)
#influence.measures(mod1)
# Shapiro-Wilk Test
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(mod1))
# Durbin-Watson Test
dwtest(mod1)
pchisq(deviance(mod1), df.residual(mod1), lower=FALSE)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod1$fitted.values)
LRT <- deviance(mod1) - deviance(fmod)
1-pchisq(LRT, df.residual(mod1)-df.residual(fmod))
drop1(fmod, test="F")
summary(mod1)
predv <- data.frame(Age = 22, Sex = 0, Income = 20, Months = 6, Hours = 25, CreditCard = 0, Facebook = 1)
predict(mod1, newdata=predv, se.fit=T, type="response")
hosmerlem(newdata$Buy, mod1$fitted.values)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(newdata$Buy, mod1$fitted.values)
hosmerlem(data$Buy, mod1$fitted.values)
hosmerlem(newdata$Buy, mod1$fitted.values)
newdata <- data[-c(4,37,395),]
mod1 <- glm(Buy~., data=newdata, family=binomial(link="logit"))
summary(mod1)
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(mod1))
# Durbin-Watson Test
dwtest(mod1)
pchisq(deviance(mod1), df.residual(mod1), lower=FALSE)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(newdata$Buy, mod1$fitted.values)
LRT <- deviance(mod1) - deviance(fmod)
1-pchisq(LRT, df.residual(mod1)-df.residual(fmod))
summary(mod1)
mod1 <- glm(Buy~Income+Months+CreditCard, data=newdata, family=binomial(link="logit"))
summary(mod1)
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(mod1))
# Durbin-Watson Test
dwtest(mod1)
pchisq(deviance(mod1), df.residual(mod1), lower=FALSE)
LRT <- deviance(mod1) - deviance(fmod)
1-pchisq(LRT, df.residual(mod1)-df.residual(fmod))
summary(mod1)
predv <- data.frame(Age = 22, Sex = 0, Income = 20, Months = 6, Hours = 25, CreditCard = 0, Facebook = 1)
predict(mod1, newdata=predv, se.fit=T, type="response")
mod1 <- update(mod1, data=newdata)
summary(mod1)
data <- read.csv("marriott.csv", header = TRUE)
setwd("~/Master/Time Serie Analysis/Case 1")
library(forecast)
data <- read.csv("marriott.csv", header = TRUE)
names(data) <- tolower(names(data))
# Build Regression Model
data$t <- 1:nrow(data)
lm <- lm(pickup.ratio~t, data=data[1:87,])
summary(lm)
# Insert trend and detrend column
data$pickup.ratio.trend <- (lm$coefficients[1] + (lm$coefficients[2] * data$t))
data$pickup.ratio.detrend <- data$pickup.ratio/data$pickup.ratio.trend
# Calculate Seasonal
df <- data[1:87,]
seasonal <- aggregate(df$pickup.ratio.detrend, list(df$dow.indicator), FUN=mean)
seasonal <- seasonal[,2]+(1-mean(seasonal[,2]))
# Attach Seasonal Column
data$seasonal <- rep(seasonal,14)
# Calculate Multi Decomposed pickup.ratio
data$pickup.ratio.multidecompose <- data$pickup.ratio.trend*data$seasonal
# Self-validation
accuracy(data$pickup.ratio.multidecompose[1:87], data$pickup.ratio[1:87])
# Plot pickup.ratio
plot(data$t, data$pickup.ratio, col = "red", type = 'l')
# Plot pickup.ratio
plot(data$t, data$pickup.ratio, col = "red", type = 'l')
lines(data$t, data$pickup.ratio.multidecompose, col = "blue")
# Calculate Multi Decomposed demand
data$demand.multidecompose <- (data$pickup.ratio.multidecompose * data$tuesday.bookings)
plot(data$t, data$demand, col = "red", type = 'l')
lines(data$t, data$demand.multidecompose, col = "blue")
# Plot demand
plot(data$t, data$demand, col = "red", type = 'l', ylim=2200)
lines(data$t, data$demand.multidecompose, col = "blue")
?plot
# Plot demand
plot(data$t, data$demand, col = "red", type = 'l')
lines(data$t, data$demand.multidecompose, col = "blue")
# Read data
data <- read.csv("marriott.csv", header = TRUE)
names(data) <- tolower(names(data))
# Build Regression Model
data$t <- 1:nrow(data)
lm <- lm(pickup.ratio~t, data=data[1:87,])
summary(lm)
# Insert trend and detrend column
data$pickup.ratio.trend <- (lm$coefficients[1] + (lm$coefficients[2] * data$t))
data$pickup.ratio.detrend <- data$pickup.ratio/data$pickup.ratio.trend
# Calculate Seasonal
df <- data[1:87,]
seasonal <- aggregate(df$pickup.ratio.detrend, list(df$dow.indicator), FUN=mean)
seasonal <- seasonal[,2]+(1-mean(seasonal[,2]))
# Attach Seasonal Column
data$seasonal <- rep(seasonal,14)
# Calculate Multi Decomposed pickup.ratio
data$pickup.ratio.multidecompose <- data$pickup.ratio.trend*data$seasonal
# Self-validation
accuracy(data$pickup.ratio.multidecompose[1:87], data$pickup.ratio[1:87])
# Plot pickup.ratio
plot(data$t, data$pickup.ratio, col = "red", type = 'l')
lines(data$t, data$pickup.ratio.multidecompose, col = "blue")
# Calculate Multi Decomposed demand
data$demand.multidecompose <- (data$pickup.ratio.multidecompose * data$tuesday.bookings)
# Plot demand
plot(data$t, data$demand, col = "red", type = 'l')
lines(data$t, data$demand.multidecompose, col = "blue")
#lines(data$t, data$tuesday.bookings, col = "darkgreen")
# Forecast for Saturday August 22.
data$demand.multidecompose[92]
setwd("~/Master/Time Serie Analysis/Case 1")
library(forecast)
# Model 1 (demand as a response variable)
# Read data
data <- read.csv("marriott.csv", header = TRUE)
names(data) <- tolower(names(data))
# Build Regression Model
data$t <- 1:nrow(data)
lm <- lm(demand~t, data=data[1:87,])
summary(lm)
# Insert trend and detrend column
data$demand.trend <- (lm$coefficients[1] + (lm$coefficients[2] * data$t))
data$demand.detrend <- data$demand/data$demand.trend
# Calculate Seasonal
df <- data[1:87,]
seasonal <- aggregate(df$demand.detrend, list(df$dow.indicator), FUN=mean)
seasonal <- seasonal[,2]+(1-mean(seasonal[,2]))
# Attach Seasonal Column
data$seasonal <- rep(seasonal,14)
# Calculate Multi Decomposed Demand
data$demand.multidecompose <- data$demand.trend*data$seasonal
# Self-validation
accuracy(data$demand.multidecompose[1:87], data$demand[1:87])
# Plot
plot(data$t, data$demand, col = "red", type = 'l')
lines(data$t, data$demand.multidecompose, col = "blue")
# Forecast for Saturday August 22.
data$demand.multidecompose[92]
# Read data
data <- read.csv("marriott.csv", header = TRUE)
names(data) <- tolower(names(data))
# Build Regression Model
data$t <- 1:nrow(data)
lm <- lm(pickup.ratio~t, data=data[1:87,])
summary(lm)
# Insert trend and detrend column
data$pickup.ratio.trend <- (lm$coefficients[1] + (lm$coefficients[2] * data$t))
data$pickup.ratio.detrend <- data$pickup.ratio/data$pickup.ratio.trend
# Calculate Seasonal
df <- data[1:87,]
seasonal <- aggregate(df$pickup.ratio.detrend, list(df$dow.indicator), FUN=mean)
seasonal <- seasonal[,2]+(1-mean(seasonal[,2]))
# Attach Seasonal Column
data$seasonal <- rep(seasonal,14)
# Calculate Multi Decomposed pickup.ratio
data$pickup.ratio.multidecompose <- data$pickup.ratio.trend*data$seasonal
# Self-validation
accuracy(data$pickup.ratio.multidecompose[1:87], data$pickup.ratio[1:87])
# Plot pickup.ratio
plot(data$t, data$pickup.ratio, col = "red", type = 'l')
lines(data$t, data$pickup.ratio.multidecompose, col = "blue")
# Calculate Multi Decomposed demand
data$demand.multidecompose <- (data$pickup.ratio.multidecompose * data$tuesday.bookings)
# Plot demand
plot(data$t, data$demand, col = "red", type = 'l')
lines(data$t, data$demand.multidecompose, col = "blue")
#lines(data$t, data$tuesday.bookings, col = "darkgreen")
# Forecast for Saturday August 22.
data$demand.multidecompose[92]
setwd("~/Master/Time Serie Analysis/Case 1")
data <- read.csv("marriott.csv", header = TRUE)
base <- data[1:87,]
# Add deseasonalized demand column
base$de.DEMAND <- base$DEMAND/base$DOW.INDEX
head(base)
tail(base)
summary(base)
# Create time series object
ts.demand <- ts(base$de.DEMAND)
par(mfrow=c(1,1))
plot(ts.demand, type='l')
# Model
model <- ets(ts.demand)
model #ANN
par(mfrow = c(1, 1))
plot(forecast(model, h = 5))
# Forecast
forecast(model, h = 5, level = 0)
# Self-validation
forecast <- forecast(model)$fitted
accuracy(forecast,ts.demand)
# Forecast for Saturday, August 22,
sat.forecast <- round(1405.645*data[1,6],0)
sat.forecast
model %>% checkresiduals()
setwd("~/Master/Time Serie Analysis/Case 1")
data <- read.csv('marriott.csv', sep=',', header=TRUE)
newdata <- data[0:87,]
library(forecast)
library(zoo)
newdata['DE_PICKUP_RATIO'] <- newdata['PICKUP.RATIO']/newdata['DOW.INDEX']
newdata['DE_DEMAND'] <- newdata['DEMAND']/newdata['DOW.INDEX']
de_pickup <- ts(newdata['DE_PICKUP_RATIO'])
pickup <- ts(newdata['PICKUP.RATIO'])
de_demand <- ts(newdata['DE_DEMAND'])
demand <- ts(newdata['DEMAND'])
bestmodel <- ets(de_pickup)
forecast <- forecast(bestmodel)$fitted
accuracy(forecast,de_pickup)
bestmodel
forecast(bestmodel, h=5)
bestmodel %>% checkresiduals()
?pt
# Check Residuals
model %>% checkresiduals()
bestmodel %>% checkresiduals()
checkresiduals(bestmodel)
test <- checkresiduals(bestmodel)
test[2]
test[1]
test[2]
pt(12.55,test[2])
pt(12.55,8)
pt(0.1, 8)
pt(1.1939, 8)
pt(0.988, 8)
pt(0.8544, 8)
